version: '3.8'
services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app
    restart: unless-stopped
    depends_on:
      - database
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
    restart: unless-stopped
  database:
    build: ./database
    environment:
      POSTGRES_DB: med_db
      POSTGRES_USER: med_user
      POSTGRES_PASSWORD: med_pass
    ports:
      - "5432:5432"
    volumes:
      - db_data:/var/lib/postgresql/data
    restart: unless-stopped
  qwen-embedding:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.8
    ports:
      - "9977:80"
    command:
      [
        "--model-id","Qwen/Qwen3-Embedding-0.6B",
        "--revision","refs/pr/27",
        "--max-batch-tokens","2048",
        "--max-batch-requests","4",
        "--max-concurrent-requests","4",
        "--tokenization-workers","2",
        "--auto-truncate"
      ]
    environment:
      OMP_NUM_THREADS: "1"
      OPENBLAS_NUM_THREADS: "1"
      MKL_NUM_THREADS: "1"
      NUMEXPR_NUM_THREADS: "1"
      BLIS_NUM_THREADS: "1"
      VECLIB_MAXIMUM_THREADS: "1"
      ORT_THREAD_POOL_SIZE: "1"
      ORT_DISABLE_MEMORY_ARENA: "1"
      KMP_AFFINITY: "granularity=fine,compact,1,0"
      KMP_BLOCKTIME: "0"
      RUST_LOG: "error"
    restart: unless-stopped
volumes:
  db_data:
